{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer learning... \n",
    "\n",
    "Transfer learning as an approach that allows to train models using pretrained weights.. VGG16, RESNet-50, Inception are well known models that have been trained on very large datasets and have state of art results.. \n",
    "\n",
    "We will use these models weight to train our network to predict dog's breed.. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "pre_trained_features = np.load('pretrained-model-weights/DogResnet50Data.npz')\n",
    "train_ResNet50 = pre_trained_features['train']\n",
    "valid_ResNet50 = pre_trained_features['valid']\n",
    "test_ResNet50 = pre_trained_features['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data for training and validation ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 133 total dog categories.\n",
      "There are 8351 total dog images.\n",
      "\n",
      "There are 6680 training dog images.\n",
      "There are 835 validation dog images.\n",
      "There are 836 test dog images.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_files       \n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    dog_files = np.array(data['filenames'])\n",
    "    dog_targets = np_utils.to_categorical(np.array(data['target']), 133)\n",
    "    return dog_files, dog_targets\n",
    "\n",
    "# load train, test, and validation datasets\n",
    "train_files, train_targets = load_dataset('dogImages/train')\n",
    "valid_files, valid_targets = load_dataset('dogImages/valid')\n",
    "test_files, test_targets = load_dataset('dogImages/test')\n",
    "\n",
    "dog_names = [item[20:-1] for item in sorted(glob(\"dogImages/train/*/\"))]\n",
    "\n",
    "# print statistics about the dataset\n",
    "print('There are %d total dog categories.' % len(dog_names))\n",
    "print('There are %s total dog images.\\n' % len(np.hstack([train_files, valid_files, test_files])))\n",
    "print('There are %d training dog images.' % len(train_files))\n",
    "print('There are %d validation dog images.' % len(valid_files))\n",
    "print('There are %d test dog images.'% len(test_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model architecture using ResNet_pre_trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "global_average_pooling2d_1 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 133)               272517    \n",
      "=================================================================\n",
      "Total params: 272,517\n",
      "Trainable params: 272,517\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense, Activation\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "ResNet_model = Sequential()\n",
    "ResNet_model.add(GlobalAveragePooling2D(input_shape=train_ResNet50.shape[1:]))\n",
    "ResNet_model.add(Dense(133, activation='softmax'))\n",
    "\n",
    "ResNet_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model compilation..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam, Adamax\n",
    "\n",
    "ResNet_model.compile(loss='categorical_crossentropy', optimizer=Adamax(lr=0.002), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6680 samples, validate on 835 samples\n",
      "Epoch 1/30\n",
      "6680/6680 [==============================] - 1s - loss: 2.3979 - acc: 0.4858 - val_loss: 1.2498 - val_acc: 0.7114\n",
      "Epoch 2/30\n",
      "6680/6680 [==============================] - 0s - loss: 0.7923 - acc: 0.8377 - val_loss: 0.8952 - val_acc: 0.7701\n",
      "Epoch 3/30\n",
      "6680/6680 [==============================] - 0s - loss: 0.5228 - acc: 0.8994 - val_loss: 0.7702 - val_acc: 0.8012\n",
      "Epoch 4/30\n",
      "6680/6680 [==============================] - 0s - loss: 0.3850 - acc: 0.9364 - val_loss: 0.6922 - val_acc: 0.8036\n",
      "Epoch 5/30\n",
      "6680/6680 [==============================] - 0s - loss: 0.2968 - acc: 0.9584 - val_loss: 0.6472 - val_acc: 0.8084\n",
      "Epoch 6/30\n",
      "6680/6680 [==============================] - 1s - loss: 0.2383 - acc: 0.9717 - val_loss: 0.6253 - val_acc: 0.8240\n",
      "Epoch 7/30\n",
      "6680/6680 [==============================] - 0s - loss: 0.1938 - acc: 0.9814 - val_loss: 0.6081 - val_acc: 0.8216\n",
      "Epoch 8/30\n",
      "6680/6680 [==============================] - 0s - loss: 0.1600 - acc: 0.9876 - val_loss: 0.5900 - val_acc: 0.8156\n",
      "Epoch 9/30\n",
      "6680/6680 [==============================] - 1s - loss: 0.1332 - acc: 0.9924 - val_loss: 0.5690 - val_acc: 0.8299\n",
      "Epoch 10/30\n",
      "6680/6680 [==============================] - 0s - loss: 0.1125 - acc: 0.9940 - val_loss: 0.5591 - val_acc: 0.8311\n",
      "Epoch 11/30\n",
      "6680/6680 [==============================] - 0s - loss: 0.0969 - acc: 0.9960 - val_loss: 0.5477 - val_acc: 0.8455\n",
      "Epoch 12/30\n",
      "6680/6680 [==============================] - 0s - loss: 0.0827 - acc: 0.9967 - val_loss: 0.5457 - val_acc: 0.8299\n",
      "Epoch 13/30\n",
      "6680/6680 [==============================] - 0s - loss: 0.0717 - acc: 0.9979 - val_loss: 0.5398 - val_acc: 0.8395\n",
      "Epoch 14/30\n",
      "6680/6680 [==============================] - 0s - loss: 0.0624 - acc: 0.9987 - val_loss: 0.5334 - val_acc: 0.8419\n",
      "Epoch 15/30\n",
      "6680/6680 [==============================] - 0s - loss: 0.0541 - acc: 0.9990 - val_loss: 0.5330 - val_acc: 0.8371\n",
      "Epoch 16/30\n",
      "6680/6680 [==============================] - 0s - loss: 0.0475 - acc: 0.9988 - val_loss: 0.5344 - val_acc: 0.8359\n",
      "Epoch 17/30\n",
      "6680/6680 [==============================] - 0s - loss: 0.0422 - acc: 0.9985 - val_loss: 0.5367 - val_acc: 0.8443\n",
      "Epoch 18/30\n",
      "6680/6680 [==============================] - 0s - loss: 0.0379 - acc: 0.9987 - val_loss: 0.5334 - val_acc: 0.8383\n",
      "Epoch 19/30\n",
      "6680/6680 [==============================] - 0s - loss: 0.0334 - acc: 0.9985 - val_loss: 0.5254 - val_acc: 0.8479\n",
      "Epoch 20/30\n",
      "6680/6680 [==============================] - 0s - loss: 0.0297 - acc: 0.9988 - val_loss: 0.5376 - val_acc: 0.8407\n",
      "Epoch 21/30\n",
      "6680/6680 [==============================] - 0s - loss: 0.0267 - acc: 0.9984 - val_loss: 0.5356 - val_acc: 0.8443\n",
      "Epoch 22/30\n",
      "6680/6680 [==============================] - 0s - loss: 0.0241 - acc: 0.9988 - val_loss: 0.5441 - val_acc: 0.8395\n",
      "Epoch 23/30\n",
      "6680/6680 [==============================] - 0s - loss: 0.0217 - acc: 0.9988 - val_loss: 0.5299 - val_acc: 0.8467\n",
      "Epoch 24/30\n",
      "6680/6680 [==============================] - 0s - loss: 0.0196 - acc: 0.9985 - val_loss: 0.5290 - val_acc: 0.8491\n",
      "Epoch 25/30\n",
      "6680/6680 [==============================] - 0s - loss: 0.0178 - acc: 0.9988 - val_loss: 0.5345 - val_acc: 0.8491\n",
      "Epoch 26/30\n",
      "6680/6680 [==============================] - 0s - loss: 0.0162 - acc: 0.9988 - val_loss: 0.5435 - val_acc: 0.8431\n",
      "Epoch 27/30\n",
      "6680/6680 [==============================] - 0s - loss: 0.0148 - acc: 0.9988 - val_loss: 0.5287 - val_acc: 0.8467\n",
      "Epoch 28/30\n",
      "6680/6680 [==============================] - 0s - loss: 0.0135 - acc: 0.9987 - val_loss: 0.5364 - val_acc: 0.8539\n",
      "Epoch 29/30\n",
      "6680/6680 [==============================] - 1s - loss: 0.0124 - acc: 0.9987 - val_loss: 0.5383 - val_acc: 0.8479\n",
      "Epoch 30/30\n",
      "6680/6680 [==============================] - 0s - loss: 0.0115 - acc: 0.9990 - val_loss: 0.5434 - val_acc: 0.8551\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1793b799ef0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint  \n",
    "epochs = 30\n",
    "batch_size = 64\n",
    "## comment out this line if you are interested to save the checkpoints... \n",
    "\n",
    "#checkpointer = ModelCheckpoint(filepath='saved_models/weights.best_adamax.ResNet50.hdf5', \n",
    "#                               verbose=1, save_best_only=True)\n",
    "\n",
    "#ResNet_model.fit(train_ResNet50, train_targets, \n",
    "#          validation_data=(valid_ResNet50, valid_targets),\n",
    "#          epochs=epochs, batch_size=batch_size, callbacks=[checkpointer], verbose=1)\n",
    "\n",
    "\n",
    "\n",
    "ResNet_model.fit(train_ResNet50, train_targets, \n",
    "          validation_data=(valid_ResNet50, valid_targets),\n",
    "          epochs=epochs, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 84.3301%\n"
     ]
    }
   ],
   "source": [
    "ResNet50_predictions = [np.argmax(ResNet_model.predict(np.expand_dims(feature, axis=0))) for feature in test_ResNet50]\n",
    "\n",
    "# report test accuracy\n",
    "test_accuracy = 100*np.sum(np.array(ResNet50_predictions)==np.argmax(test_targets, axis=1))/len(ResNet50_predictions)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
